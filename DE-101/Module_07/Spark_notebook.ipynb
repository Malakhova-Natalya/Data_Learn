{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6ecc4e98",
   "metadata": {},
   "source": [
    "# Jupyter Notebook & Spark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32d13fda",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Содержание<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Налаживаем-взаимодействие-Jupyter-Notebook-и-Spark\" data-toc-modified-id=\"Налаживаем-взаимодействие-Jupyter-Notebook-и-Spark-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Налаживаем взаимодействие Jupyter Notebook и Spark</a></span></li><li><span><a href=\"#Пробуем-Spark-в-деле:-считаем-M&amp;Ms\" data-toc-modified-id=\"Пробуем-Spark-в-деле:-считаем-M&amp;Ms-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Пробуем Spark в деле: считаем M&amp;Ms</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b812e3f3",
   "metadata": {},
   "source": [
    "## Налаживаем взаимодействие Jupyter Notebook и Spark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47ce7424",
   "metadata": {},
   "source": [
    "Действуем по статье: [Get Started with PySpark and Jupyter Notebook in 3 Minutes](https://medium.com/sicara/get-started-pyspark-jupyter-guide-tutorial-ae2fe84f594f#:~:text=There%20are%20two%20ways%20to%20get%20PySpark%20available,Jupyter%20Notebook%20and%20load%20PySpark%20using%20findSpark%20package)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7cae5ac",
   "metadata": {},
   "source": [
    "Загружаем findspark (делается один раз, затем можно закомментировать):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "640edbaf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#pip install findspark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f0d5e96",
   "metadata": {},
   "source": [
    "Устанавливаем необходимые библиотеки:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f58a68f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "import pyspark\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "255afec3",
   "metadata": {},
   "source": [
    "Запускаем небольшую программу из статьи:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "085b3410",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.1415942\n"
     ]
    }
   ],
   "source": [
    "sc = pyspark.SparkContext(appName=\"Pi\")\n",
    "num_samples = 100000000\n",
    "def inside(p):     \n",
    "  x, y = random.random(), random.random()\n",
    "  return x*x + y*y < 1\n",
    "count = sc.parallelize(range(0, num_samples)).filter(inside).count()\n",
    "pi = 4 * count / num_samples\n",
    "print(pi)\n",
    "sc.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca4c77e1",
   "metadata": {},
   "source": [
    "## Пробуем Spark в деле: считаем M&Ms "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d378b0e",
   "metadata": {},
   "source": [
    "Теперь опробуем программу подсчёта M&Ms. Импортируем библиотеки:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "62983042",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3192ddef",
   "metadata": {},
   "source": [
    "Задаём Спарк-сессию:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a7a7de4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = (SparkSession\n",
    "        .builder\n",
    "        .appName(\"PythonMnMCount\")\n",
    "        .getOrCreate())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "354dacca",
   "metadata": {},
   "source": [
    "Задаём путь к файлу, читаем его и выводим 5 строк:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1e6e89cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------+-----+\n",
      "|State|Color |Count|\n",
      "+-----+------+-----+\n",
      "|TX   |Red   |20   |\n",
      "|NV   |Blue  |66   |\n",
      "|CO   |Blue  |79   |\n",
      "|OR   |Blue  |71   |\n",
      "|WA   |Yellow|93   |\n",
      "+-----+------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# get the M&M data set file name\n",
    "mnm_file = '/C:/datasets/mnm_dataset.csv'\n",
    "\n",
    "# read the file into a Spark DataFrame\n",
    "mnm_df = (spark.read.format(\"csv\")\n",
    "        .option(\"header\", \"true\")\n",
    "        .option(\"inferSchema\", \"true\")\n",
    "        .load(mnm_file))\n",
    "\n",
    "# show 5 rows\n",
    "mnm_df.show(n=5, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "140508b4",
   "metadata": {},
   "source": [
    "Делаем трансофрмацию исходного файла и выводим 60 строк - штаты и цвета M&Ms с наибольшим количеством:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "93a58463",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------+----------+\n",
      "|State|Color |sum(Count)|\n",
      "+-----+------+----------+\n",
      "|CA   |Yellow|100956    |\n",
      "|WA   |Green |96486     |\n",
      "|CA   |Brown |95762     |\n",
      "|TX   |Green |95753     |\n",
      "|TX   |Red   |95404     |\n",
      "|CO   |Yellow|95038     |\n",
      "|NM   |Red   |94699     |\n",
      "|OR   |Orange|94514     |\n",
      "|WY   |Green |94339     |\n",
      "|NV   |Orange|93929     |\n",
      "|TX   |Yellow|93819     |\n",
      "|CO   |Green |93724     |\n",
      "|CO   |Brown |93692     |\n",
      "|CA   |Green |93505     |\n",
      "|NM   |Brown |93447     |\n",
      "|CO   |Blue  |93412     |\n",
      "|WA   |Red   |93332     |\n",
      "|WA   |Brown |93082     |\n",
      "|WA   |Yellow|92920     |\n",
      "|NM   |Yellow|92747     |\n",
      "|NV   |Brown |92478     |\n",
      "|TX   |Orange|92315     |\n",
      "|AZ   |Brown |92287     |\n",
      "|AZ   |Green |91882     |\n",
      "|WY   |Red   |91768     |\n",
      "|AZ   |Orange|91684     |\n",
      "|CA   |Red   |91527     |\n",
      "|WA   |Orange|91521     |\n",
      "|NV   |Yellow|91390     |\n",
      "|UT   |Orange|91341     |\n",
      "|NV   |Green |91331     |\n",
      "|NM   |Orange|91251     |\n",
      "|NM   |Green |91160     |\n",
      "|WY   |Blue  |91002     |\n",
      "|UT   |Red   |90995     |\n",
      "|CO   |Orange|90971     |\n",
      "|AZ   |Yellow|90946     |\n",
      "|TX   |Brown |90736     |\n",
      "|OR   |Blue  |90526     |\n",
      "|CA   |Orange|90311     |\n",
      "|OR   |Red   |90286     |\n",
      "|NM   |Blue  |90150     |\n",
      "|AZ   |Red   |90042     |\n",
      "|NV   |Blue  |90003     |\n",
      "|UT   |Blue  |89977     |\n",
      "|AZ   |Blue  |89971     |\n",
      "|WA   |Blue  |89886     |\n",
      "|OR   |Green |89578     |\n",
      "|CO   |Red   |89465     |\n",
      "|NV   |Red   |89346     |\n",
      "|UT   |Yellow|89264     |\n",
      "|OR   |Brown |89136     |\n",
      "|CA   |Blue  |89123     |\n",
      "|UT   |Brown |88973     |\n",
      "|TX   |Blue  |88466     |\n",
      "|UT   |Green |88392     |\n",
      "|OR   |Yellow|88129     |\n",
      "|WY   |Orange|87956     |\n",
      "|WY   |Yellow|87800     |\n",
      "|WY   |Brown |86110     |\n",
      "+-----+------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# aggregate count of all colors and groupBy state and color\n",
    "# orderBy descending order\n",
    "count_mnm_df = (mnm_df.select(\"State\", \"Color\", \"Count\")\n",
    "                    .groupBy(\"State\", \"Color\")\n",
    "                    .sum(\"Count\")\n",
    "                    .orderBy(\"sum(Count)\", ascending=False))\n",
    "\n",
    "# show all the resulting aggregation for all the dates and colors\n",
    "count_mnm_df.show(n=60, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96f4ac92",
   "metadata": {},
   "source": [
    "Убеждаемся, что у нас именно 60 строк:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a1625f3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Rows = 60\n"
     ]
    }
   ],
   "source": [
    "print(\"Total Rows = %d\" % (count_mnm_df.count()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a7d3bc3",
   "metadata": {},
   "source": [
    "И ещё раз трансформируем наш файл - выводим данные только для штата Калифорния:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1ab8906a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------+----------+\n",
      "|State|Color |sum(Count)|\n",
      "+-----+------+----------+\n",
      "|CA   |Yellow|100956    |\n",
      "|CA   |Brown |95762     |\n",
      "|CA   |Green |93505     |\n",
      "|CA   |Red   |91527     |\n",
      "|CA   |Orange|90311     |\n",
      "|CA   |Blue  |89123     |\n",
      "+-----+------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# find the aggregate count for California by filtering\n",
    "ca_count_mnm_df = (mnm_df.select(\"*\")\n",
    "                       .where(mnm_df.State == 'CA')\n",
    "                       .groupBy(\"State\", \"Color\")\n",
    "                       .sum(\"Count\")\n",
    "                       .orderBy(\"sum(Count)\", ascending=False))\n",
    "\n",
    "# show the resulting aggregation for California\n",
    "ca_count_mnm_df.show(n=10, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8695d9a7",
   "metadata": {},
   "source": [
    "Готово! Spark работает, и его удобно запускать через Jupyter Notebook (особенно если вы выпускник Яндекс Практикума 😉)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Содержание",
   "title_sidebar": "Содержание",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
